{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveragePrice  Total Volume  region\n",
       "0          1.33      64236.62  Albany\n",
       "1          1.35      54876.98  Albany\n",
       "2          0.93     118220.22  Albany\n",
       "3          1.08      78992.15  Albany\n",
       "4          1.28      51039.60  Albany"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/avocado.csv')\n",
    "df = df[[\"AveragePrice\", \"Total Volume\", \"region\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AveragePrice  Total Volume\n",
       "region                            \n",
       "Albany          1.33      64236.62\n",
       "Albany          1.35      54876.98\n",
       "Albany          0.93     118220.22\n",
       "Albany          1.08      78992.15\n",
       "Albany          1.28      51039.60"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index(\"region\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NewYork</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1129876.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NewYork</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1139347.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NewYork</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1254805.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NewYork</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1068971.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewYork</td>\n",
       "      <td>1.16</td>\n",
       "      <td>999169.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1.60</td>\n",
       "      <td>100274.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1.73</td>\n",
       "      <td>97026.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1.75</td>\n",
       "      <td>94441.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1.68</td>\n",
       "      <td>106624.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87517.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         region  AveragePrice  Total Volume\n",
       "0       NewYork          1.17    1129876.05\n",
       "1       NewYork          1.23    1139347.98\n",
       "2       NewYork          1.12    1254805.29\n",
       "3       NewYork          1.20    1068971.54\n",
       "4       NewYork          1.16     999169.64\n",
       "..          ...           ...           ...\n",
       "671  LosAngeles          1.60     100274.88\n",
       "672  LosAngeles          1.73      97026.15\n",
       "673  LosAngeles          1.75      94441.50\n",
       "674  LosAngeles          1.68     106624.63\n",
       "675  LosAngeles          1.80      87517.23\n",
       "\n",
       "[676 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = df.loc[[\"NewYork\",\"LosAngeles\"]]\n",
    "cities = cities.reset_index()\n",
    "#print(cities.groupby('region').size())\n",
    "cities.head()\n",
    "cities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         region  AveragePrice  Total Volume\n",
      "286     NewYork          2.04      63623.43\n",
      "591  LosAngeles          1.14     108031.14\n",
      "128     NewYork          1.57    1327763.45\n",
      "387  LosAngeles          0.89    2800679.50\n",
      "32      NewYork          1.43    1255552.68\n",
      "..          ...           ...           ...\n",
      "262     NewYork          1.96      33409.96\n",
      "191     NewYork          1.91      12784.61\n",
      "596  LosAngeles          1.05     108798.33\n",
      "180     NewYork          2.09      12517.38\n",
      "481  LosAngeles          0.98    3100355.01\n",
      "\n",
      "[676 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_shuffled=sklearn.utils.shuffle(cities)\n",
    "print(df_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities['region'] = cities['region'].replace(['Houston'],1)\n",
    "cities['region'] = cities['region'].replace(['LosAngeles'],1)\n",
    "cities['region'] = cities['region'].replace(['NewYork'],2)\n",
    "# cities['region'] = cities['region'].replace(['PhoenixTucson'],4)\n",
    "# cities['region'] = cities['region'].replace(['SanFrancisco'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region\n",
      "1    338\n",
      "2    338\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cities[\"region\"] = pd.to_numeric(cities[\"region\"])\n",
    "print(cities.groupby('region').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WestTexNewMexico</th>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WestTexNewMexico</th>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WestTexNewMexico</th>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WestTexNewMexico</th>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WestTexNewMexico</th>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AveragePrice  Total Volume\n",
       "region                                      \n",
       "Albany                    1.33      64236.62\n",
       "Albany                    1.35      54876.98\n",
       "Albany                    0.93     118220.22\n",
       "Albany                    1.08      78992.15\n",
       "Albany                    1.28      51039.60\n",
       "...                        ...           ...\n",
       "WestTexNewMexico          1.63      17074.83\n",
       "WestTexNewMexico          1.71      13888.04\n",
       "WestTexNewMexico          1.87      13766.76\n",
       "WestTexNewMexico          1.93      16205.22\n",
       "WestTexNewMexico          1.62      17489.58\n",
       "\n",
       "[18249 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.17</td>\n",
       "      <td>1129876.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.23</td>\n",
       "      <td>1139347.98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.12</td>\n",
       "      <td>1254805.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.20</td>\n",
       "      <td>1068971.54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.16</td>\n",
       "      <td>999169.64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveragePrice  Total Volume  region\n",
       "0          1.17    1129876.05       2\n",
       "1          1.23    1139347.98       2\n",
       "2          1.12    1254805.29       2\n",
       "3          1.20    1068971.54       2\n",
       "4          1.16     999169.64       2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.head()\n",
    "cities = cities[[\"AveragePrice\", \"Total Volume\", \"region\"]]\n",
    "cities.head()\n",
    "average price, volumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.17000000e+00, 1.12987605e+06, 2.00000000e+00],\n",
       "       [1.23000000e+00, 1.13934798e+06, 2.00000000e+00],\n",
       "       [1.12000000e+00, 1.25480529e+06, 2.00000000e+00],\n",
       "       ...,\n",
       "       [1.75000000e+00, 9.44415000e+04, 1.00000000e+00],\n",
       "       [1.68000000e+00, 1.06624630e+05, 1.00000000e+00],\n",
       "       [1.80000000e+00, 8.75172300e+04, 1.00000000e+00]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = cities.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.17000000e+00 1.12987605e+06]\n",
      " [1.23000000e+00 1.13934798e+06]\n",
      " [1.12000000e+00 1.25480529e+06]\n",
      " ...\n",
      " [1.75000000e+00 9.44415000e+04]\n",
      " [1.68000000e+00 1.06624630e+05]\n",
      " [1.80000000e+00 8.75172300e+04]]\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,0:2]\n",
    "print(X)\n",
    "Y = dataset[:,2]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30188679, 0.20532361],\n",
       "       [0.33018868, 0.20705783],\n",
       "       [0.27830189, 0.22819695],\n",
       "       ...,\n",
       "       [0.5754717 , 0.01574553],\n",
       "       [0.54245283, 0.01797615],\n",
       "       [0.5990566 , 0.01447777]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(473, 2) (101, 2) (102, 2) (473,) (101,) (102,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building and training neural network\n",
    "\n",
    "# setting up the architecture\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(2,)),\n",
    "    Dense(32, activation='softmax'), # neurons\n",
    "    Dense(32, activation='relu'), # neurons\n",
    "    Dense(32, activation='softmax'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring it for compiling\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='kullback_leibler_divergence',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 473 samples, validate on 101 samples\n",
      "Epoch 1/45\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 2/45\n",
      "473/473 [==============================] - 0s 197us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 3/45\n",
      "473/473 [==============================] - 0s 199us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 4/45\n",
      "473/473 [==============================] - 0s 185us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 5/45\n",
      "473/473 [==============================] - 0s 233us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 6/45\n",
      "473/473 [==============================] - 0s 190us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 7/45\n",
      "473/473 [==============================] - 0s 209us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 8/45\n",
      "473/473 [==============================] - 0s 205us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 9/45\n",
      "473/473 [==============================] - 0s 245us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 10/45\n",
      "473/473 [==============================] - 0s 247us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 11/45\n",
      "473/473 [==============================] - 0s 239us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 12/45\n",
      "473/473 [==============================] - 0s 229us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 13/45\n",
      "473/473 [==============================] - 0s 278us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 14/45\n",
      "473/473 [==============================] - 0s 194us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 15/45\n",
      "473/473 [==============================] - 0s 264us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 16/45\n",
      "473/473 [==============================] - 0s 352us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 17/45\n",
      "473/473 [==============================] - 0s 229us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 18/45\n",
      "473/473 [==============================] - 0s 174us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 19/45\n",
      "473/473 [==============================] - 0s 253us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 20/45\n",
      "473/473 [==============================] - 0s 204us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 21/45\n",
      "473/473 [==============================] - 0s 234us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 22/45\n",
      "473/473 [==============================] - 0s 190us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 23/45\n",
      "473/473 [==============================] - 0s 220us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 24/45\n",
      "473/473 [==============================] - 0s 307us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 25/45\n",
      "473/473 [==============================] - 0s 273us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 26/45\n",
      "473/473 [==============================] - 0s 214us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 27/45\n",
      "473/473 [==============================] - 0s 204us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 28/45\n",
      "473/473 [==============================] - 0s 204us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 29/45\n",
      "473/473 [==============================] - 0s 236us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 30/45\n",
      "473/473 [==============================] - 0s 218us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 31/45\n",
      "473/473 [==============================] - 0s 247us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 32/45\n",
      "473/473 [==============================] - 0s 198us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 33/45\n",
      "473/473 [==============================] - 0s 242us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 34/45\n",
      "473/473 [==============================] - 0s 230us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 35/45\n",
      "473/473 [==============================] - 0s 179us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 36/45\n",
      "473/473 [==============================] - 0s 214us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 37/45\n",
      "473/473 [==============================] - 0s 187us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 38/45\n",
      "473/473 [==============================] - 0s 202us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 39/45\n",
      "473/473 [==============================] - 0s 201us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 40/45\n",
      "473/473 [==============================] - 0s 200us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 41/45\n",
      "473/473 [==============================] - 0s 234us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 42/45\n",
      "473/473 [==============================] - 0s 285us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 43/45\n",
      "473/473 [==============================] - 0s 236us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 44/45\n",
      "473/473 [==============================] - 0s 215us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n",
      "Epoch 45/45\n",
      "473/473 [==============================] - 0s 178us/step - loss: 0.0000e+00 - accuracy: 0.4947 - val_loss: 0.0000e+00 - val_accuracy: 0.5248\n"
     ]
    }
   ],
   "source": [
    "# training our model\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=45,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 138us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)[1] # viewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_accuracy': [0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347, 0.5247524976730347], 'loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'accuracy': [0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146, 0.4947146]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeWUlEQVR4nO3df7xVdZ3v8dfbAwKJPxBQkIPANcbQUmr2ZbKahn4+8EdhE44wU+FYmSQlTd4iH2Va40x5MZ0xbw4maWVydShDr2RKmnZnajgQIogmclGPECAlSKJw8HP/WN+Dm80+5+ylZ519fryfj8d+nLW+6/td+7OWPvabtdbeaykiMDMzq9VB9S7AzMx6FgeHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODrM2SBorKST1q6HvOZJ+1RV1mdWbg8N6BUkbJO2WNKyifWX68B9bp9LMeh0Hh/Um/w+Y0Toj6U3AoPqV0z3UcsRkloeDw3qTHwAfK5ufCXy/vIOkwyV9X9JWSU9K+rKkg9KyBknzJD0raT1wepWxN0jaJOkZSf8oqaGWwiTdJun3krZLekDSiWXLBkm6MtWzXdKvJA1Ky94h6T8kPSfpaUnnpPb7JX2ibB37nSpLR1kXSHoceDy1/Utaxw5JyyX9ZVn/BkkXS3pC0vNp+WhJ10q6smJb7pA0p5bttt7JwWG9ya+BwyRNSB/oZwM/rOhzDXA48N+AvyILmr9Pyz4JnAG8GSgB0yrG3gS0AK9Pfd4PfILaLAHGA0cBK4Cby5bNA/4ceBtwJPAF4GVJx6Zx1wDDgYnAyhrfD+BM4C+AE9L8srSOI4EfAbdJGpiW/QPZ0dppwGHAucALZNs8oyxchwHvAW7JUYf1NhHhl189/gVsAN4LfBn4Z2AKcA/QDwhgLNAAvAScUDbuU8D9afoXwPlly96fxvYDjk5jB5UtnwHcl6bPAX5VY61HpPUeTvaPt13AyVX6fQn4SRvruB/4RNn8fu+f1v/uDur4Y+v7Ao8BU9votxZ4X5qeDdxV7//eftX35XOf1tv8AHgAGEfFaSpgGHAw8GRZ25PAqDR9DPB0xbJWY4D+wCZJrW0HVfSvKh39XA6cRXbk8HJZPQOAgcATVYaObqO9VvvVJunzZEdIx5AFy2Gpho7e6ybgI2RB/BHgX15DTdYL+FSV9SoR8STZRfLTgB9XLH4W2EMWAq2OBZ5J05vIPkDLl7V6muyIY1hEHJFeh0XEiXTsb4GpZEdEh5Md/QAo1fQicFyVcU+30Q7wJ+B1ZfMjqvTZd+vrdD3ji8DfAEMi4ghge6qho/f6ITBV0snABOD2NvpZH+HgsN7o42Snaf5U3hgRe4FbgcslHSppDNm5/dbrILcCn5XUKGkIMLds7Cbg58CVkg6TdJCk4yT9VQ31HEoWOtvIPuz/qWy9LwMLgG9JOiZdpD5F0gCy6yDvlfQ3kvpJGippYhq6EvhrSa+T9Pq0zR3V0AJsBfpJuoTsiKPVd4GvSxqvzEmShqYam8muj/wAWBQRu2rYZuvFHBzW60TEExHR1Mbiz5D9a3098Cuyi8QL0rLrgbuBh8guYFcesXyM7FTXI2TXB/4dGFlDSd8nO+31TBr764rlFwEPk304/wH4JnBQRDxFduT0+dS+Ejg5jbkK2A1sJjuVdDPtu5vsQvvvUi0vsv+prG+RBefPgR3ADez/VeabgDeRhYf1cYrwg5zMrH2S3kl2ZDY2HSVZH+YjDjNrl6T+wIXAdx0aBg4OM2uHpAnAc2Sn5K6uazHWbfhUlZmZ5eIjDjMzy6VP/ABw2LBhMXbs2HqXYWbWoyxfvvzZiBhe2d4ngmPs2LE0NbX17UwzM6tG0pPV2n2qyszMcnFwmJlZLg4OMzPLpdDgkDRF0mOS1kmaW2X55PTgmpXpdUlqHy3pPklrJa2RdGHZmEvTQ3Rax5xW5DaYmdn+Crs4nm4lfS3wPqAZWCZpcUQ8UtH1wYg4o6KtBfh8RKyQdCiwXNI9ZWOvioh5RdVuZmZtK/KIYxKwLiLWR8RuYCHZraU7FBGbImJFmn6e7EEyo9ofZWZmXaHI4BjF/nffbKb6h/8pkh6StKT8OcytJI0le0znb8qaZ0taJWlBuv21mZl1kSJ/x6EqbZX3N1kBjImInelaxe1kz2XOViANBhYBcyJiR2r+DvD1tK6vA1eSPR95/zeXzgPOAzj22GMrF9dmyVz4/cOvbqyZWXcw4k1w6jc6dZVFHnE0s//T1BqBjeUdImJHROxM03cB/SUNg3135FwE3BwRPy4bszki9qa7dF5PdkrsABExPyJKEVEaPvyAHz6amdmrVOQRxzJgvKRxZA+wmU72CM19JI0ANkdESJpEFmTblD3U+QZgbUR8q2LMyPQ0NoAPAasL24JOTmkzs96gsOCIiBZJs8mePNYALIiINZLOT8uvA6YBsyS1ALuA6SlE3gF8FHhY0sq0yovTUckV6fGZAWwAPlXUNpiZ2YH6xG3VS6VS+F5VZmb5SFoeEaXKdv9y3MzMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlkuhwSFpiqTHJK2TNLfK8smStktamV6XpPbRku6TtFbSGkkXlo05UtI9kh5Pf4cUuQ1mZra/woJDUgNwLXAqcAIwQ9IJVbo+GBET0+trqa0F+HxETADeClxQNnYusDQixgNL07yZmXWRIo84JgHrImJ9ROwGFgJTaxkYEZsiYkWafh5YC4xKi6cCN6Xpm4AzO7NoMzNrX5HBMQp4umy+mVc+/MudIukhSUsknVi5UNJY4M3Ab1LT0RGxCbKAAY7q1KrNzKxd/Qpct6q0RcX8CmBMROyUdBpwOzB+3wqkwcAiYE5E7Mj15tJ5wHkAxx57bJ6hZmbWjiKPOJqB0WXzjcDG8g4RsSMidqbpu4D+koYBSOpPFho3R8SPy4ZtljQy9RkJbKn25hExPyJKEVEaPnx4Z22TmVmfV2RwLAPGSxon6WBgOrC4vIOkEZKUpieleralthuAtRHxrYr1LgZmpumZwE8L3AYzM6tQ2KmqiGiRNBu4G2gAFkTEGknnp+XXAdOAWZJagF3A9IgISe8APgo8LGllWuXF6ajkG8Ctkj4OPAWcVdQ2mJnZgRRRedmh9ymVStHU1FTvMszMehRJyyOiVNnuX46bmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxyKTQ4JE2R9JikdZLmVlk+WdJ2SSvT65KyZQskbZG0umLMpZKeKRtzWpHbYGZm++tX1IolNQDXAu8DmoFlkhZHxCMVXR+MiDOqrOJG4NvA96ssuyoi5nVmvWZmVpsijzgmAesiYn1E7AYWAlNrHRwRDwB/KKo4MzN7dYoMjlHA02Xzzamt0imSHpK0RNKJNa57tqRV6XTWkGodJJ0nqUlS09atW3OWbmZmbSkyOFSlLSrmVwBjIuJk4Brg9hrW+x3gOGAisAm4slqniJgfEaWIKA0fPrzWms3MrANFBkczMLpsvhHYWN4hInZExM40fRfQX9Kw9lYaEZsjYm9EvAxcT3ZKzMzMukiRwbEMGC9pnKSDgenA4vIOkkZIUpqelOrZ1t5KJY0sm/0QsLqtvmZm1vkK+1ZVRLRImg3cDTQACyJijaTz0/LrgGnALEktwC5gekQEgKRbgMnAMEnNwFcj4gbgCkkTyU57bQA+VdQ2mJnZgZQ+p3u1UqkUTU1N9S7DzKxHkbQ8IkqV7f7luJmZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5dJhcEg6Q5IDxszMgNqOOKYDj0u6QtKEogsyM7PurcPgiIiPAG8GngC+J+k/00OSDi28OjMz63ZqOgUVETuARWSPfx1JdjvzFZI+U2BtZmbWDdVyjeMDkn4C/ALoD0yKiFOBk4GLCq7PzMy6mVqex3EWcFVEPFDeGBEvSDq3mLLMzKy7qiU4vkr2bG8AJA0Cjo6IDRGxtLDKzMysW6rlGsdtwMtl83tTm5mZ9UG1BEe/iNjdOpOmDy6uJDMz685qCY6tkj7YOiNpKvBscSWZmVl3Vss1jvOBmyV9GxDwNPCxQqsyM7Nuq8PgiIgngLdKGgwoIp4vviwzM+uuajniQNLpwInAQEkARMTXCqzLzMy6qVp+AHgdcDbwGbJTVWcBYwquy8zMuqlaLo6/LSI+BvwxIi4DTgFGF1uWmZl1V7UEx4vp7wuSjgH2AONqWbmkKZIek7RO0twqyydL2i5pZXpdUrZsgaQtklZXjDlS0j2SHk9/h9RSi5mZdY5aguMOSUcA/xNYAWwAbulokKQG4FrgVOAEYIakE6p0fTAiJqZX+XWTG4EpVfrPBZZGxHhgaZo3M7Mu0m5wpAc4LY2I5yJiEdm1jTdExCXtjUsmAesiYn360eBCYGqthaV7Y/2hyqKpwE1p+ibgzFrXaWZmr127wRERLwNXls2/FBHba1z3KLLffLRqTm2VTpH0kKQlkk6sYb1HR8SmVM8m4KhqndIzQ5okNW3durXGks3MrCO1nKr6uaQPq/V7uLWr1j8q5lcAYyLiZOAa4Pac79GmiJgfEaWIKA0fPryzVmtm1ufVEhz/QHZTw5ck7ZD0vKQdNYxrZv9vXzUCG8s7RMSOiNiZpu8C+ksa1sF6N0saCZD+bqmhFjMz6yS1PDr20Ig4KCIOjojD0vxhNax7GTBe0jhJB5M9u3xxeQdJI1qPZCRNSvVs62C9i4GZaXom8NMaajEzs07S4S/HJb2zWnvlg52qLG+RNBu4G2gAFkTEGknnp+XXAdOAWZJagF3A9IiI9L63AJOBYZKaga9GxA3AN4BbJX0ceIrsB4lmZtZFlD6n2+4g3VE2O5Ds21LLI+LdRRbWmUqlUjQ1NdW7DDOzHkXS8ogoVbbXcpPDD1SsaDRwRSfWZmZmPUgtF8crNQNv7OxCzMysZ6jlGsc1vPI12oOAicBDBdZkZmbdWC23VS+/ONAC3BIR/7egeszMrJurJTj+HXgxIvZCdg8qSa+LiBeKLc3MzLqjWq5xLAUGlc0PAu4tphwzM+vuagmOga2/7gZI068rriQzM+vOagmOP0l6S+uMpD8n+7GemZn1QbVc45gD3Cap9T5TI8keJWtmZn1QLT8AXCbpDcDxZHe8fTQi9hRemZmZdUsdnqqSdAFwSESsjoiHgcGSPl18aWZm1h3Vco3jkxHxXOtMRPwR+GRhFZmZWbdWS3AcVP4Qp/Qs8YOLK8nMzLqzWi6O3012G/PryG49cj6wpNCqzMys26olOL4InAfMIrs4/luyb1aZmVkfVMsTAF8Gfg2sB0rAe4C1BddlZmbdVJtHHJL+jOxxrzPIHuf6vwEi4l1dU5qZmXVH7Z2qehR4EPhARKwDkPS5LqnKzMy6rfZOVX0Y+D1wn6TrJb2H7BqHmZn1YW0GR0T8JCLOBt4A3A98Djha0nckvb+L6jMzs26mlovjf4qImyPiDKARWAnMLbowMzPrnnI9czwi/hAR/xYR7y6qIDMz695yBYeZmZmDw8zMcik0OCRNkfSYpHWSDrguImmypO2SVqbXJR2NlXSppGfKxpxW5DaYmdn+arnlyKuSboZ4LfA+oBlYJmlxRDxS0fXBdOE9z9irImJeUbWbmVnbijzimASsi4j1EbEbWAhM7YKxZmZWoCKDYxTwdNl8c2qrdIqkhyQtkXRijWNnS1olaYGkIdXeXNJ5kpokNW3duvU1bIaZmZUrMjiq/co8KuZXAGMi4mTgGuD2GsZ+BzgOmAhsAq6s9uYRMT8iShFRGj58eL7KzcysTUUGRzMwumy+EdhY3iEidkTEzjR9F9Bf0rD2xkbE5ojYm+7aez3ZaS0zM+siRQbHMmC8pHGSDia70+7i8g6SRrQ+XVDSpFTPtvbGSip/FsiHgNUFboOZmVUo7FtVEdEiaTbZEwQbgAURsUbS+Wn5dcA0YJakFmAXMD0iAqg6Nq36CkkTyU5dbQA+VdQ2mJnZgZR9TvdupVIpmpqa6l2GmVmPIml5RJQq2/3LcTMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS6FBoekKZIek7RO0twqyydL2i5pZXpd0tFYSUdKukfS4+nvkCK3wczM9ldYcEhqAK4FTgVOAGZIOqFK1wcjYmJ6fa2GsXOBpRExHlia5s3MrIsUecQxCVgXEesjYjewEJjaCWOnAjel6ZuAMzuvZDMz60iRwTEKeLpsvjm1VTpF0kOSlkg6sYaxR0fEJoD096hqby7pPElNkpq2bt36WrbDzMzKFBkcqtIWFfMrgDERcTJwDXB7jrHtioj5EVGKiNLw4cPzDDUzs3YUGRzNwOiy+UZgY3mHiNgRETvT9F1Af0nDOhi7WdJIgPR3SzHlm5lZNUUGxzJgvKRxkg4GpgOLyztIGiFJaXpSqmdbB2MXAzPT9EzgpwVug5mZVehX1IojokXSbOBuoAFYEBFrJJ2fll8HTANmSWoBdgHTIyKAqmPTqr8B3Crp48BTwFlFbYOZmR1I2ed071YqlaKpqaneZZiZ9SiSlkdEqbLdvxw3M7NcCjtVZWbWk+3Zs4fm5mZefPHFepdSuIEDB9LY2Ej//v1r6u/gMDOrorm5mUMPPZSxY8eSvsPTK0UE27Zto7m5mXHjxtU0xqeqzMyqePHFFxk6dGivDg0ASQwdOjTXkZWDw8ysDb09NFrl3U4Hh5mZ5eLgMDPrhrZt28bEiROZOHEiI0aMYNSoUfvmd+/e3e7YpqYmPvvZzxZWmy+Om5l1Q0OHDmXlypUAXHrppQwePJiLLrpo3/KWlhb69av+EV4qlSiVDvj5RadxcJiZdeCyO9bwyMYdnbrOE445jK9+4MSOO5Y555xzOPLII/ntb3/LW97yFs4++2zmzJnDrl27GDRoEN/73vc4/vjjuf/++5k3bx533nknl156KU899RTr16/nqaeeYs6cOa/5aMTBYWbWg/zud7/j3nvvpaGhgR07dvDAAw/Qr18/7r33Xi6++GIWLVp0wJhHH32U++67j+eff57jjz+eWbNm1fybjWocHGZmHch7ZFCks846i4aGBgC2b9/OzJkzefzxx5HEnj17qo45/fTTGTBgAAMGDOCoo45i8+bNNDY2vuoafHHczKwHOeSQQ/ZNf+UrX+Fd73oXq1ev5o477mjztxgDBgzYN93Q0EBLS8trqsHBYWbWQ23fvp1Ro7KHo954441d9r4ODjOzHuoLX/gCX/rSl3j729/O3r17u+x9fVt1M7Mq1q5dy4QJE+pdRpeptr2+rbqZmXUKB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OM7NuaPLkydx99937tV199dV8+tOfbrN/V/3swMFhZtYNzZgxg4ULF+7XtnDhQmbMmFGnil7hmxyamXVkyVz4/cOdu84Rb4JTv9Hm4mnTpvHlL3+Zl156iQEDBrBhwwY2btzIj370Iz73uc+xa9cupk2bxmWXXda5ddWg0CMOSVMkPSZpnaS57fT775L2SppW1nahpNWS1kiaU9Z+qaRnJK1Mr9OK3AYzs3oYOnQokyZN4mc/+xmQHW2cffbZXH755TQ1NbFq1Sp++ctfsmrVqi6vrbAjDkkNwLXA+4BmYJmkxRHxSJV+3wTuLmt7I/BJYBKwG/iZpP8TEY+nLldFxLyiajcz2087RwZFaj1dNXXqVBYuXMiCBQu49dZbmT9/Pi0tLWzatIlHHnmEk046qUvrKvKIYxKwLiLWR8RuYCEwtUq/zwCLgC1lbROAX0fECxHRAvwS+FCBtZqZdTtnnnkmS5cuZcWKFezatYshQ4Ywb948li5dyqpVqzj99NPbvJV6kYoMjlHA02XzzaltH0mjyALhuoqxq4F3Shoq6XXAacDosuWzJa2StEDSkGpvLuk8SU2SmrZu3fpat8XMrMsNHjyYyZMnc+655zJjxgx27NjBIYccwuGHH87mzZtZsmRJXeoq8uK4qrRV3or3auCLEbFXeqV7RKyV9E3gHmAn8BDQ+uSR7wBfT+v6OnAlcO4BbxQxH5gP2d1xX80GFPGcYTPrGS548yAO3rqz3mXwrtPO5Lbb/o4r/tcNDD7mOF4/4Y382RsmMHrMWCaW/oItz7/IE1t3smvPXpr/+AJDKmoe1L+BY44Y1Kk1FRkczex/lNAIbKzoUwIWptAYBpwmqSUibo+IG4AbACT9U1ofEbG5dbCk64E7C9sCM7M6e//pH2Tdluf3zV9xzb9V7fej27vu6KPI4FgGjJc0DngGmA78bXmHiBjXOi3pRuDOiLg9zR8VEVskHQv8NXBKah8ZEZvSsA+RndYqRHd6zrCZda21a9dy3PDB9S6jWyosOCKiRdJssm9LNQALImKNpPPT8srrGpUWSRoK7AEuiIg/pvYrJE0kO1W1AfhUEfWbmVl1hf4AMCLuAu6qaKsaGBFxTsX8X7bR76OdVZ+ZWXsigvLrr71V3ifB+pYjZmZVDBw4kG3btuX+UO1pIoJt27YxcODAmsf4liNmZlU0NjbS3NxMX/g6/8CBA2lsbKy5v4PDzKyK/v37M27cuI479kE+VWVmZrk4OMzMLBcHh5mZ5aLe/o0BAElbgSdf5fBhwLOdWE5v4H1SnffLgbxPDtST9smYiBhe2dgnguO1kNQUEaV619GdeJ9U5/1yIO+TA/WGfeJTVWZmlouDw8zMcnFwdGx+vQvohrxPqvN+OZD3yYF6/D7xNQ4zM8vFRxxmZpaLg8PMzHJxcLRD0hRJj0laJ2luveuph/Rc9y2SVpe1HSnpHkmPp79Vn/veW0kaLek+SWslrZF0YWrvs/tF0kBJ/yXpobRPLkvtfXaftJLUIOm3ku5M8z1+nzg42iCpAbgWOBU4AZgh6YT6VlUXNwJTKtrmAksjYjywNM33JS3A5yNiAvBW4IL0/0Zf3i8vAe+OiJOBicAUSW+lb++TVhcCa8vme/w+cXC0bRKwLiLWR8RuYCEwtc41dbmIeAD4Q0XzVOCmNH0TcGZX1lRvEbEpIlak6efJPhRG0Yf3S2R2ptn+6RX04X0CIKkROB34bllzj98nDo62jQKeLptvTm0GR7c+9z39ParO9dSNpLHAm4Hf0Mf3SzolsxLYAtwTEX1+nwBXA18AXi5r6/H7xMHRtmrPi/R3l20fSYOBRcCciNhR73rqLSL2RsREoBGYJOmNdS6priSdAWyJiOX1rqWzOTja1gyMLptvBDbWqZbuZrOkkQDp75Y619PlJPUnC42bI+LHqbnP7xeAiHgOuJ/s2lhf3idvBz4oaQPZqe53S/ohvWCfODjatgwYL2mcpIOB6cDiOtfUXSwGZqbpmcBP61hLl5Mk4AZgbUR8q2xRn90vkoZLOiJNDwLeCzxKH94nEfGliGiMiLFknx+/iIiP0Av2iX853g5Jp5Gdo2wAFkTE5fWtqOtJugWYTHYr6M3AV4HbgVuBY4GngLMiovICeq8l6R3Ag8DDvHLu+mKy6xx9cr9IOonsQm8D2T9Ib42Ir0kaSh/dJ+UkTQYuiogzesM+cXCYmVkuPlVlZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw6wTSNoraWXZq9NuXCdpbPndic3qrV+9CzDrJXal222Y9Xo+4jArkKQNkr6ZnlXxX5Jen9rHSFoqaVX6e2xqP1rST9JzLR6S9La0qgZJ16dnXfw8/TrbrC4cHGadY1DFqaqzy5btiIhJwLfJ7kRAmv5+RJwE3Az8a2r/V+CX6bkWbwHWpPbxwLURcSLwHPDhQrfGrB3+5bhZJ5C0MyIGV2nfQPaAo/Xpxoi/j4ihkp4FRkbEntS+KSKGSdoKNEbES2XrGEt2m/Lxaf6LQP+I+Mcu2DSzA/iIw6x40cZ0W32qealsei++Pml15OAwK97ZZX//M03/B9kdUwH+DvhVml4KzIJ9D0Y6rKuKNKuV/9Vi1jkGpafftfpZRLR+JXeApN+Q/UNtRmr7LLBA0v8AtgJ/n9ovBOZL+jjZkcUsYFPRxZvl4WscZgVK1zhKEfFsvWsx6yw+VWVmZrn4iMPMzHLxEYeZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLv8fEyyV1mdVAVAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graphing the accuracy \n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.17, 1129876.05] => 1 (expected 2)\n",
      "[1.23, 1139347.98] => 1 (expected 2)\n",
      "[1.12, 1254805.29] => 1 (expected 2)\n",
      "[1.2, 1068971.54] => 1 (expected 2)\n",
      "[1.16, 999169.64] => 1 (expected 2)\n",
      "[1.14, 1111803.12] => 1 (expected 2)\n",
      "[1.04, 1357393.34] => 1 (expected 2)\n",
      "[1.13, 1406262.16] => 1 (expected 2)\n",
      "[1.06, 2180520.22] => 1 (expected 2)\n",
      "[1.23, 1048045.86] => 1 (expected 2)\n",
      "[0.97, 1856337.85] => 1 (expected 2)\n",
      "[1.28, 1099283.22] => 1 (expected 2)\n",
      "[1.26, 1342963.26] => 1 (expected 2)\n",
      "[1.16, 1201066.41] => 1 (expected 2)\n",
      "[1.18, 1192210.54] => 1 (expected 2)\n",
      "[1.16, 1479334.84] => 1 (expected 2)\n",
      "[1.22, 1340925.56] => 1 (expected 2)\n",
      "[1.22, 1251081.11] => 1 (expected 2)\n",
      "[1.1, 1477964.12] => 1 (expected 2)\n",
      "[1.14, 1535981.4] => 1 (expected 2)\n",
      "[1.1, 1563915.04] => 1 (expected 2)\n",
      "[1.14, 1458722.6] => 1 (expected 2)\n",
      "[1.28, 1211731.19] => 1 (expected 2)\n",
      "[1.37, 1251919.24] => 1 (expected 2)\n",
      "[1.27, 1338282.24] => 1 (expected 2)\n",
      "[1.18, 1666825.63] => 1 (expected 2)\n",
      "[1.36, 1284789.44] => 1 (expected 2)\n",
      "[1.28, 1667026.11] => 1 (expected 2)\n",
      "[1.32, 1363133.97] => 1 (expected 2)\n",
      "[1.32, 1731061.12] => 1 (expected 2)\n",
      "[1.43, 1493218.75] => 1 (expected 2)\n",
      "[1.37, 1515022.63] => 1 (expected 2)\n",
      "[1.43, 1255552.68] => 1 (expected 2)\n",
      "[1.22, 2118593.92] => 1 (expected 2)\n",
      "[1.32, 1679103.39] => 1 (expected 2)\n",
      "[1.44, 1295589.61] => 1 (expected 2)\n",
      "[1.42, 1332514.63] => 1 (expected 2)\n",
      "[1.43, 1084407.8] => 1 (expected 2)\n",
      "[1.41, 1244324.47] => 1 (expected 2)\n",
      "[1.36, 1183815.23] => 1 (expected 2)\n",
      "[1.33, 1192732.41] => 1 (expected 2)\n",
      "[1.45, 1097737.98] => 1 (expected 2)\n",
      "[1.36, 1129333.95] => 1 (expected 2)\n",
      "[1.18, 1338129.89] => 1 (expected 2)\n",
      "[1.33, 1088977.45] => 1 (expected 2)\n",
      "[1.36, 997562.44] => 1 (expected 2)\n",
      "[1.11, 1658708.73] => 1 (expected 2)\n",
      "[1.36, 1433763.11] => 1 (expected 2)\n",
      "[1.36, 1102868.27] => 1 (expected 2)\n",
      "[1.37, 1044280.56] => 1 (expected 2)\n",
      "[1.34, 1018225.83] => 1 (expected 2)\n",
      "[1.09, 1402890.2] => 1 (expected 2)\n",
      "[1.36, 1087984.9] => 1 (expected 2)\n",
      "[1.26, 1241381.71] => 1 (expected 2)\n",
      "[1.32, 1163696.14] => 1 (expected 2)\n",
      "[1.52, 960475.67] => 1 (expected 2)\n",
      "[1.56, 970753.07] => 1 (expected 2)\n",
      "[1.59, 1093097.04] => 1 (expected 2)\n",
      "[1.9, 830018.48] => 1 (expected 2)\n",
      "[1.93, 767190.62] => 1 (expected 2)\n",
      "[1.99, 618279.77] => 1 (expected 2)\n",
      "[1.95, 807564.93] => 1 (expected 2)\n",
      "[1.89, 969846.54] => 1 (expected 2)\n",
      "[1.76, 1031060.45] => 1 (expected 2)\n",
      "[1.72, 1057930.65] => 1 (expected 2)\n",
      "[1.62, 1061132.87] => 1 (expected 2)\n",
      "[1.5, 1108446.44] => 1 (expected 2)\n",
      "[1.26, 1558413.54] => 1 (expected 2)\n",
      "[1.47, 1278749.25] => 1 (expected 2)\n",
      "[1.58, 1212399.97] => 1 (expected 2)\n",
      "[1.47, 1334937.86] => 1 (expected 2)\n",
      "[1.49, 1275952.93] => 1 (expected 2)\n",
      "[1.54, 1256917.91] => 1 (expected 2)\n",
      "[1.7, 1122162.86] => 1 (expected 2)\n",
      "[1.68, 1180373.67] => 1 (expected 2)\n",
      "[1.64, 1076259.08] => 1 (expected 2)\n",
      "[1.51, 1266199.75] => 1 (expected 2)\n",
      "[1.53, 1280725.34] => 1 (expected 2)\n",
      "[1.2, 1622151.78] => 1 (expected 2)\n",
      "[1.5, 1372612.33] => 1 (expected 2)\n",
      "[1.44, 1485642.35] => 1 (expected 2)\n",
      "[1.47, 1447580.25] => 1 (expected 2)\n",
      "[1.08, 1827100.26] => 1 (expected 2)\n",
      "[1.14, 1586647.62] => 1 (expected 2)\n",
      "[1.14, 1706730.17] => 1 (expected 2)\n",
      "[0.77, 2740587.86] => 1 (expected 2)\n",
      "[1.22, 1536109.56] => 1 (expected 2)\n",
      "[1.12, 1718055.86] => 1 (expected 2)\n",
      "[1.08, 1030786.84] => 1 (expected 2)\n",
      "[1.09, 987897.9] => 1 (expected 2)\n",
      "[1.31, 1240608.2] => 1 (expected 2)\n",
      "[1.32, 1395562.08] => 1 (expected 2)\n",
      "[1.09, 1743194.56] => 1 (expected 2)\n",
      "[1.17, 1600417.32] => 1 (expected 2)\n",
      "[1.24, 1455656.4] => 1 (expected 2)\n",
      "[1.15, 1594427.98] => 1 (expected 2)\n",
      "[1.21, 1315177.5] => 1 (expected 2)\n",
      "[1.09, 1806980.64] => 1 (expected 2)\n",
      "[0.95, 2202127.86] => 1 (expected 2)\n",
      "[1.02, 1615465.33] => 1 (expected 2)\n",
      "[1.3, 1429242.83] => 1 (expected 2)\n",
      "[1.01, 1840344.27] => 1 (expected 2)\n",
      "[1.15, 1364272.64] => 1 (expected 2)\n",
      "[1.07, 1454164.32] => 1 (expected 2)\n",
      "[1.33, 1201219.44] => 1 (expected 2)\n",
      "[1.34, 1233461.89] => 1 (expected 2)\n",
      "[1.41, 1181560.33] => 1 (expected 2)\n",
      "[1.14, 2390308.58] => 1 (expected 2)\n",
      "[1.41, 1191930.0] => 1 (expected 2)\n",
      "[1.42, 1210256.0] => 1 (expected 2)\n",
      "[1.37, 1335298.0] => 1 (expected 2)\n",
      "[1.52, 1122350.0] => 1 (expected 2)\n",
      "[1.41, 1319642.14] => 1 (expected 2)\n",
      "[1.57, 1217806.97] => 1 (expected 2)\n",
      "[1.54, 1253047.6] => 1 (expected 2)\n",
      "[1.68, 1176751.31] => 1 (expected 2)\n",
      "[1.69, 1105462.53] => 1 (expected 2)\n",
      "[1.67, 1201890.84] => 1 (expected 2)\n",
      "[1.65, 1178504.26] => 1 (expected 2)\n",
      "[1.61, 1154925.12] => 1 (expected 2)\n",
      "[1.61, 1150959.1] => 1 (expected 2)\n",
      "[1.8, 1077993.21] => 1 (expected 2)\n",
      "[1.81, 1100987.66] => 1 (expected 2)\n",
      "[1.75, 1057188.97] => 1 (expected 2)\n",
      "[1.58, 1267239.35] => 1 (expected 2)\n",
      "[1.56, 1277419.69] => 1 (expected 2)\n",
      "[1.52, 1306226.34] => 1 (expected 2)\n",
      "[1.55, 1306877.98] => 1 (expected 2)\n",
      "[1.57, 1327763.45] => 1 (expected 2)\n",
      "[1.63, 1442667.56] => 1 (expected 2)\n",
      "[1.72, 1304560.72] => 1 (expected 2)\n",
      "[1.47, 1521598.08] => 1 (expected 2)\n",
      "[1.82, 1242160.85] => 1 (expected 2)\n",
      "[1.74, 1374185.78] => 1 (expected 2)\n",
      "[1.83, 1335461.36] => 1 (expected 2)\n",
      "[1.75, 1451146.59] => 1 (expected 2)\n",
      "[1.8, 1298242.54] => 1 (expected 2)\n",
      "[1.75, 1387420.96] => 1 (expected 2)\n",
      "[1.65, 1746824.6] => 1 (expected 2)\n",
      "[1.84, 1228100.25] => 1 (expected 2)\n",
      "[1.68, 1247609.13] => 1 (expected 2)\n",
      "[1.76, 1222890.71] => 1 (expected 2)\n",
      "[1.75, 1277721.97] => 1 (expected 2)\n",
      "[1.74, 1221327.78] => 1 (expected 2)\n",
      "[1.72, 1154893.52] => 1 (expected 2)\n",
      "[1.7, 1155875.16] => 1 (expected 2)\n",
      "[1.76, 1163703.37] => 1 (expected 2)\n",
      "[1.39, 1465568.77] => 1 (expected 2)\n",
      "[1.55, 1241381.61] => 1 (expected 2)\n",
      "[1.28, 1052132.16] => 1 (expected 2)\n",
      "[1.19, 1955395.44] => 1 (expected 2)\n",
      "[1.24, 2544483.08] => 1 (expected 2)\n",
      "[1.52, 1270564.47] => 1 (expected 2)\n",
      "[1.48, 1721917.04] => 1 (expected 2)\n",
      "[1.38, 1384264.04] => 1 (expected 2)\n",
      "[1.29, 1532074.69] => 1 (expected 2)\n",
      "[1.44, 940983.17] => 1 (expected 2)\n",
      "[1.34, 1774776.77] => 1 (expected 2)\n",
      "[1.43, 1564859.63] => 1 (expected 2)\n",
      "[1.35, 1755052.38] => 1 (expected 2)\n",
      "[1.23, 1931495.66] => 1 (expected 2)\n",
      "[1.3, 1615325.14] => 1 (expected 2)\n",
      "[1.24, 1413687.38] => 1 (expected 2)\n",
      "[1.27, 2051389.99] => 1 (expected 2)\n",
      "[1.28, 2959541.38] => 1 (expected 2)\n",
      "[1.2, 2278728.69] => 1 (expected 2)\n",
      "[1.27, 2135242.76] => 1 (expected 2)\n",
      "[1.67, 1294149.71] => 1 (expected 2)\n",
      "[1.67, 1287480.31] => 1 (expected 2)\n",
      "[1.9, 21565.58] => 1 (expected 2)\n",
      "[1.93, 24549.47] => 1 (expected 2)\n",
      "[1.9, 23927.09] => 1 (expected 2)\n",
      "[1.65, 18494.23] => 1 (expected 2)\n",
      "[1.89, 9962.63] => 1 (expected 2)\n",
      "[1.84, 13438.23] => 1 (expected 2)\n",
      "[1.76, 13622.89] => 1 (expected 2)\n",
      "[1.82, 13935.65] => 1 (expected 2)\n",
      "[2.09, 12422.6] => 1 (expected 2)\n",
      "[1.94, 15727.43] => 1 (expected 2)\n",
      "[2.07, 12935.87] => 1 (expected 2)\n",
      "[2.09, 12517.38] => 1 (expected 2)\n",
      "[2.25, 15454.59] => 1 (expected 2)\n",
      "[2.22, 17054.18] => 1 (expected 2)\n",
      "[2.01, 17916.34] => 1 (expected 2)\n",
      "[2.18, 14667.53] => 1 (expected 2)\n",
      "[2.01, 19296.46] => 1 (expected 2)\n",
      "[2.24, 16541.9] => 1 (expected 2)\n",
      "[2.28, 15343.33] => 1 (expected 2)\n",
      "[2.3, 16293.09] => 1 (expected 2)\n",
      "[1.98, 17137.24] => 1 (expected 2)\n",
      "[2.12, 13852.18] => 1 (expected 2)\n",
      "[1.91, 12784.61] => 1 (expected 2)\n",
      "[2.2, 13745.4] => 1 (expected 2)\n",
      "[2.02, 10799.02] => 1 (expected 2)\n",
      "[2.24, 9519.72] => 1 (expected 2)\n",
      "[1.93, 16746.9] => 1 (expected 2)\n",
      "[2.34, 15733.14] => 1 (expected 2)\n",
      "[2.0, 22931.78] => 1 (expected 2)\n",
      "[2.31, 15733.56] => 1 (expected 2)\n",
      "[1.93, 17646.52] => 1 (expected 2)\n",
      "[2.17, 18746.25] => 1 (expected 2)\n",
      "[2.06, 21815.46] => 1 (expected 2)\n",
      "[1.93, 23195.0] => 1 (expected 2)\n",
      "[2.14, 18576.24] => 1 (expected 2)\n",
      "[2.21, 16170.46] => 1 (expected 2)\n",
      "[2.04, 24265.78] => 1 (expected 2)\n",
      "[1.86, 25674.65] => 1 (expected 2)\n",
      "[2.14, 14907.54] => 1 (expected 2)\n",
      "[2.08, 16567.2] => 1 (expected 2)\n",
      "[2.02, 15438.68] => 1 (expected 2)\n",
      "[1.81, 16570.75] => 1 (expected 2)\n",
      "[1.9, 19904.38] => 1 (expected 2)\n",
      "[2.0, 20787.25] => 1 (expected 2)\n",
      "[2.21, 16620.69] => 1 (expected 2)\n",
      "[1.91, 25037.76] => 1 (expected 2)\n",
      "[1.95, 22571.11] => 1 (expected 2)\n",
      "[1.93, 24697.84] => 1 (expected 2)\n",
      "[2.02, 14337.32] => 1 (expected 2)\n",
      "[2.08, 9204.78] => 1 (expected 2)\n",
      "[2.03, 14817.97] => 1 (expected 2)\n",
      "[1.93, 17328.24] => 1 (expected 2)\n",
      "[2.17, 37438.54] => 1 (expected 2)\n",
      "[1.99, 51329.63] => 1 (expected 2)\n",
      "[2.22, 32658.97] => 1 (expected 2)\n",
      "[2.04, 45383.62] => 1 (expected 2)\n",
      "[2.38, 29117.76] => 1 (expected 2)\n",
      "[2.04, 48364.4] => 1 (expected 2)\n",
      "[2.65, 28406.0] => 1 (expected 2)\n",
      "[2.46, 25247.34] => 1 (expected 2)\n",
      "[2.25, 25450.53] => 1 (expected 2)\n",
      "[2.1, 8442.79] => 1 (expected 2)\n",
      "[2.33, 17837.78] => 1 (expected 2)\n",
      "[2.3, 26463.29] => 1 (expected 2)\n",
      "[2.41, 35543.08] => 1 (expected 2)\n",
      "[2.34, 31716.46] => 1 (expected 2)\n",
      "[2.36, 45701.82] => 1 (expected 2)\n",
      "[2.06, 70119.57] => 1 (expected 2)\n",
      "[2.15, 45204.38] => 1 (expected 2)\n",
      "[2.32, 19375.8] => 1 (expected 2)\n",
      "[2.16, 30583.43] => 1 (expected 2)\n",
      "[2.27, 25308.77] => 1 (expected 2)\n",
      "[2.37, 27155.2] => 1 (expected 2)\n",
      "[2.41, 24047.65] => 1 (expected 2)\n",
      "[2.32, 29300.63] => 1 (expected 2)\n",
      "[2.4, 55607.08] => 1 (expected 2)\n",
      "[2.33, 50300.29] => 1 (expected 2)\n",
      "[2.28, 46314.26] => 1 (expected 2)\n",
      "[2.23, 38645.77] => 1 (expected 2)\n",
      "[2.26, 37403.19] => 1 (expected 2)\n",
      "[1.94, 28758.83] => 1 (expected 2)\n",
      "[2.15, 31807.14] => 1 (expected 2)\n",
      "[2.15, 34505.47] => 1 (expected 2)\n",
      "[2.01, 44794.06] => 1 (expected 2)\n",
      "[2.02, 34788.28] => 1 (expected 2)\n",
      "[2.0, 39638.67] => 1 (expected 2)\n",
      "[2.16, 54477.59] => 1 (expected 2)\n",
      "[2.11, 50334.94] => 1 (expected 2)\n",
      "[1.98, 40280.96] => 1 (expected 2)\n",
      "[2.2, 30461.39] => 1 (expected 2)\n",
      "[2.08, 47308.85] => 1 (expected 2)\n",
      "[2.12, 35908.78] => 1 (expected 2)\n",
      "[1.92, 31916.68] => 1 (expected 2)\n",
      "[1.96, 33409.96] => 1 (expected 2)\n",
      "[1.86, 41547.14] => 1 (expected 2)\n",
      "[1.96, 32608.62] => 1 (expected 2)\n",
      "[1.9, 26230.35] => 1 (expected 2)\n",
      "[2.11, 28290.46] => 1 (expected 2)\n",
      "[1.95, 30482.41] => 1 (expected 2)\n",
      "[1.83, 24749.38] => 1 (expected 2)\n",
      "[2.09, 28121.46] => 1 (expected 2)\n",
      "[1.93, 20475.96] => 1 (expected 2)\n",
      "[1.54, 34629.36] => 1 (expected 2)\n",
      "[1.61, 21072.22] => 1 (expected 2)\n",
      "[1.83, 69777.3] => 1 (expected 2)\n",
      "[1.85, 74779.73] => 1 (expected 2)\n",
      "[1.84, 75462.11] => 1 (expected 2)\n",
      "[1.79, 79929.45] => 1 (expected 2)\n",
      "[1.81, 95299.69] => 1 (expected 2)\n",
      "[2.02, 63156.0] => 1 (expected 2)\n",
      "[2.07, 68466.86] => 1 (expected 2)\n",
      "[2.05, 74312.9] => 1 (expected 2)\n",
      "[2.05, 71500.85] => 1 (expected 2)\n",
      "[2.11, 70881.96] => 1 (expected 2)\n",
      "[2.08, 70272.82] => 1 (expected 2)\n",
      "[2.09, 69241.11] => 1 (expected 2)\n",
      "[2.06, 67166.62] => 1 (expected 2)\n",
      "[2.04, 63623.43] => 1 (expected 2)\n",
      "[2.06, 70365.19] => 1 (expected 2)\n",
      "[2.08, 70931.23] => 1 (expected 2)\n",
      "[2.07, 90178.82] => 1 (expected 2)\n",
      "[2.14, 82176.04] => 1 (expected 2)\n",
      "[2.13, 73865.51] => 1 (expected 2)\n",
      "[1.85, 107274.72] => 1 (expected 2)\n",
      "[2.07, 73309.74] => 1 (expected 2)\n",
      "[1.91, 72075.29] => 1 (expected 2)\n",
      "[1.88, 71035.9] => 1 (expected 2)\n",
      "[1.85, 87888.29] => 1 (expected 2)\n",
      "[1.79, 80280.09] => 1 (expected 2)\n",
      "[2.48, 59563.6] => 1 (expected 2)\n",
      "[2.44, 63800.15] => 1 (expected 2)\n",
      "[2.36, 68542.66] => 1 (expected 2)\n",
      "[1.91, 166308.13] => 1 (expected 2)\n",
      "[2.39, 81679.26] => 1 (expected 2)\n",
      "[2.06, 112812.77] => 1 (expected 2)\n",
      "[2.38, 76002.26] => 1 (expected 2)\n",
      "[2.39, 70663.57] => 1 (expected 2)\n",
      "[2.41, 71188.47] => 1 (expected 2)\n",
      "[2.34, 88625.27] => 1 (expected 2)\n",
      "[1.9, 156250.72] => 1 (expected 2)\n",
      "[2.23, 73975.31] => 1 (expected 2)\n",
      "[1.9, 126408.2] => 1 (expected 2)\n",
      "[2.22, 69388.43] => 1 (expected 2)\n",
      "[1.86, 140039.98] => 1 (expected 2)\n",
      "[2.18, 87897.32] => 1 (expected 2)\n",
      "[1.86, 147248.57] => 1 (expected 2)\n",
      "[2.26, 93328.69] => 1 (expected 2)\n",
      "[1.81, 121542.09] => 1 (expected 2)\n",
      "[1.77, 91212.34] => 1 (expected 2)\n",
      "[1.36, 420410.54] => 1 (expected 2)\n",
      "[1.98, 59839.16] => 1 (expected 2)\n",
      "[2.03, 58560.14] => 1 (expected 2)\n",
      "[2.08, 46602.16] => 1 (expected 2)\n",
      "[2.05, 49056.11] => 1 (expected 2)\n",
      "[2.09, 42233.25] => 1 (expected 2)\n",
      "[2.15, 42755.8] => 1 (expected 2)\n",
      "[2.06, 39260.55] => 1 (expected 2)\n",
      "[1.86, 118503.55] => 1 (expected 2)\n",
      "[1.7, 189434.04] => 1 (expected 2)\n",
      "[1.92, 108114.03] => 1 (expected 2)\n",
      "[1.69, 133768.12] => 1 (expected 2)\n",
      "[1.72, 112128.84] => 1 (expected 2)\n",
      "[1.36, 495083.69] => 1 (expected 2)\n",
      "[1.92, 79877.83] => 1 (expected 2)\n",
      "[1.83, 93204.08] => 1 (expected 2)\n",
      "[1.75, 96380.28] => 1 (expected 2)\n",
      "[1.91, 71760.69] => 1 (expected 2)\n",
      "[1.91, 86632.25] => 1 (expected 2)\n",
      "[1.97, 82637.97] => 1 (expected 2)\n",
      "[0.8, 2326942.14] => 1 (expected 1)\n",
      "[0.85, 2149872.45] => 1 (expected 1)\n",
      "[0.74, 2690296.07] => 1 (expected 1)\n",
      "[0.66, 3048290.53] => 1 (expected 1)\n",
      "[0.83, 2156008.93] => 1 (expected 1)\n",
      "[0.81, 2268076.38] => 1 (expected 1)\n",
      "[0.74, 2828361.9] => 1 (expected 1)\n",
      "[0.84, 2621078.31] => 1 (expected 1)\n",
      "[0.89, 2617806.65] => 1 (expected 1)\n",
      "[0.95, 2327634.45] => 1 (expected 1)\n",
      "[0.89, 2661345.12] => 1 (expected 1)\n",
      "[0.92, 2591981.76] => 1 (expected 1)\n",
      "[0.98, 2278629.09] => 1 (expected 1)\n",
      "[0.9, 2674658.54] => 1 (expected 1)\n",
      "[0.99, 2392448.9] => 1 (expected 1)\n",
      "[0.98, 2549512.5] => 1 (expected 1)\n",
      "[0.92, 2983163.34] => 1 (expected 1)\n",
      "[0.9, 3037663.98] => 1 (expected 1)\n",
      "[1.03, 2604991.25] => 1 (expected 1)\n",
      "[0.93, 2943218.77] => 1 (expected 1)\n",
      "[0.94, 3371114.14] => 1 (expected 1)\n",
      "[1.0, 2742211.46] => 1 (expected 1)\n",
      "[0.95, 2893887.74] => 1 (expected 1)\n",
      "[1.02, 2614726.11] => 1 (expected 1)\n",
      "[1.03, 2652480.7] => 1 (expected 1)\n",
      "[0.96, 3435374.51] => 1 (expected 1)\n",
      "[0.94, 2921148.91] => 1 (expected 1)\n",
      "[0.91, 3040023.34] => 1 (expected 1)\n",
      "[0.79, 3689140.93] => 1 (expected 1)\n",
      "[0.84, 3261844.41] => 1 (expected 1)\n",
      "[0.85, 3196936.02] => 1 (expected 1)\n",
      "[0.97, 2853904.6] => 1 (expected 1)\n",
      "[0.98, 2557700.83] => 1 (expected 1)\n",
      "[0.78, 3553642.53] => 1 (expected 1)\n",
      "[0.78, 4015563.02] => 1 (expected 1)\n",
      "[1.02, 2355703.98] => 1 (expected 1)\n",
      "[0.93, 2901188.07] => 1 (expected 1)\n",
      "[0.93, 2799667.4] => 1 (expected 1)\n",
      "[1.01, 2603114.56] => 1 (expected 1)\n",
      "[1.0, 2566690.28] => 1 (expected 1)\n",
      "[1.01, 2466735.33] => 1 (expected 1)\n",
      "[0.94, 2690257.2] => 1 (expected 1)\n",
      "[0.86, 2797745.89] => 1 (expected 1)\n",
      "[0.75, 3094278.93] => 1 (expected 1)\n",
      "[0.83, 2954705.54] => 1 (expected 1)\n",
      "[0.83, 2926435.94] => 1 (expected 1)\n",
      "[0.9, 2641032.65] => 1 (expected 1)\n",
      "[0.74, 4031949.04] => 1 (expected 1)\n",
      "[0.96, 2329987.29] => 1 (expected 1)\n",
      "[0.89, 2800679.5] => 1 (expected 1)\n",
      "[0.85, 2713699.6] => 1 (expected 1)\n",
      "[0.85, 2682159.95] => 1 (expected 1)\n",
      "[0.84, 2641775.31] => 1 (expected 1)\n",
      "[0.84, 2377799.62] => 1 (expected 1)\n",
      "[0.75, 2793917.73] => 1 (expected 1)\n",
      "[0.78, 2780629.1] => 1 (expected 1)\n",
      "[1.01, 2257271.18] => 1 (expected 1)\n",
      "[1.1, 2272023.15] => 1 (expected 1)\n",
      "[1.29, 1913492.61] => 1 (expected 1)\n",
      "[1.52, 1595013.07] => 1 (expected 1)\n",
      "[1.48, 1499286.88] => 1 (expected 1)\n",
      "[1.23, 2133563.24] => 1 (expected 1)\n",
      "[1.17, 2548687.86] => 1 (expected 1)\n",
      "[1.16, 2766529.12] => 1 (expected 1)\n",
      "[1.06, 2865744.94] => 1 (expected 1)\n",
      "[1.0, 3007073.27] => 1 (expected 1)\n",
      "[1.06, 2589309.14] => 1 (expected 1)\n",
      "[0.95, 2939704.87] => 1 (expected 1)\n",
      "[0.88, 3431676.04] => 1 (expected 1)\n",
      "[0.81, 3563268.97] => 1 (expected 1)\n",
      "[0.93, 3086167.04] => 1 (expected 1)\n",
      "[1.03, 2879218.13] => 1 (expected 1)\n",
      "[1.0, 3094362.21] => 1 (expected 1)\n",
      "[1.06, 2826836.07] => 1 (expected 1)\n",
      "[1.01, 3033328.67] => 1 (expected 1)\n",
      "[0.97, 3092234.0] => 1 (expected 1)\n",
      "[0.93, 3293224.51] => 1 (expected 1)\n",
      "[0.95, 3449361.49] => 1 (expected 1)\n",
      "[0.85, 3258184.45] => 1 (expected 1)\n",
      "[0.9, 3237847.21] => 1 (expected 1)\n",
      "[0.83, 3248769.26] => 1 (expected 1)\n",
      "[0.76, 3715458.49] => 1 (expected 1)\n",
      "[0.83, 3203935.53] => 1 (expected 1)\n",
      "[0.76, 3134305.39] => 1 (expected 1)\n",
      "[0.82, 2866855.58] => 1 (expected 1)\n",
      "[0.64, 3942054.31] => 1 (expected 1)\n",
      "[0.62, 3863314.25] => 1 (expected 1)\n",
      "[0.75, 3136882.52] => 1 (expected 1)\n",
      "[0.76, 3185230.67] => 1 (expected 1)\n",
      "[0.77, 3288356.88] => 1 (expected 1)\n",
      "[0.82, 2793982.31] => 1 (expected 1)\n",
      "[0.73, 3467762.25] => 1 (expected 1)\n",
      "[0.74, 3374876.94] => 1 (expected 1)\n",
      "[0.79, 2987393.94] => 1 (expected 1)\n",
      "[0.76, 3138836.66] => 1 (expected 1)\n",
      "[0.72, 3332578.34] => 1 (expected 1)\n",
      "[0.76, 3232888.65] => 1 (expected 1)\n",
      "[0.65, 3664088.6] => 1 (expected 1)\n",
      "[0.58, 4982700.11] => 1 (expected 1)\n",
      "[0.74, 3197788.06] => 1 (expected 1)\n",
      "[0.76, 3173509.36] => 1 (expected 1)\n",
      "[0.76, 2952576.85] => 1 (expected 1)\n",
      "[0.74, 3172437.94] => 1 (expected 1)\n",
      "[0.64, 3967109.33] => 1 (expected 1)\n",
      "[0.88, 3212261.75] => 1 (expected 1)\n",
      "[1.1, 2389829.32] => 1 (expected 1)\n",
      "[0.89, 3130916.47] => 1 (expected 1)\n",
      "[1.07, 2404221.58] => 1 (expected 1)\n",
      "[1.01, 2615853.0] => 1 (expected 1)\n",
      "[1.19, 2153918.0] => 1 (expected 1)\n",
      "[1.14, 2391383.0] => 1 (expected 1)\n",
      "[1.08, 2626121.0] => 1 (expected 1)\n",
      "[1.04, 2691240.89] => 1 (expected 1)\n",
      "[1.09, 2850377.2] => 1 (expected 1)\n",
      "[1.49, 1968638.86] => 1 (expected 1)\n",
      "[1.67, 1779831.36] => 1 (expected 1)\n",
      "[1.8, 1711267.24] => 1 (expected 1)\n",
      "[1.77, 1697028.59] => 1 (expected 1)\n",
      "[1.75, 1760610.46] => 1 (expected 1)\n",
      "[1.73, 1865690.48] => 1 (expected 1)\n",
      "[1.74, 1969051.97] => 1 (expected 1)\n",
      "[1.61, 2176974.29] => 1 (expected 1)\n",
      "[1.66, 2117126.8] => 1 (expected 1)\n",
      "[1.45, 2309865.74] => 1 (expected 1)\n",
      "[1.19, 2832849.85] => 1 (expected 1)\n",
      "[1.22, 2742628.31] => 1 (expected 1)\n",
      "[1.39, 2426027.85] => 1 (expected 1)\n",
      "[1.38, 2484918.32] => 1 (expected 1)\n",
      "[1.37, 2558156.26] => 1 (expected 1)\n",
      "[1.12, 3382974.98] => 1 (expected 1)\n",
      "[1.07, 3507155.74] => 1 (expected 1)\n",
      "[0.92, 3655667.22] => 1 (expected 1)\n",
      "[0.99, 3631321.55] => 1 (expected 1)\n",
      "[0.99, 3390850.94] => 1 (expected 1)\n",
      "[0.96, 3637220.72] => 1 (expected 1)\n",
      "[1.13, 3243908.89] => 1 (expected 1)\n",
      "[1.14, 2921916.66] => 1 (expected 1)\n",
      "[0.94, 3551402.91] => 1 (expected 1)\n",
      "[0.87, 4214313.1] => 1 (expected 1)\n",
      "[0.99, 3299258.02] => 1 (expected 1)\n",
      "[1.04, 3074226.19] => 1 (expected 1)\n",
      "[1.18, 2789630.4] => 1 (expected 1)\n",
      "[1.01, 2993246.61] => 1 (expected 1)\n",
      "[0.98, 3100355.01] => 1 (expected 1)\n",
      "[1.12, 2583323.58] => 1 (expected 1)\n",
      "[1.11, 2737872.14] => 1 (expected 1)\n",
      "[1.12, 2633574.94] => 1 (expected 1)\n",
      "[0.99, 2768930.88] => 1 (expected 1)\n",
      "[0.82, 2935077.5] => 1 (expected 1)\n",
      "[0.79, 3033918.41] => 1 (expected 1)\n",
      "[0.64, 3625630.64] => 1 (expected 1)\n",
      "[0.53, 5470227.08] => 1 (expected 1)\n",
      "[0.6, 4230448.98] => 1 (expected 1)\n",
      "[0.62, 4215552.57] => 1 (expected 1)\n",
      "[0.76, 3363407.98] => 1 (expected 1)\n",
      "[0.89, 3120961.67] => 1 (expected 1)\n",
      "[0.84, 3551337.17] => 1 (expected 1)\n",
      "[1.02, 2843541.07] => 1 (expected 1)\n",
      "[0.91, 3395262.7] => 1 (expected 1)\n",
      "[1.03, 3059034.3] => 1 (expected 1)\n",
      "[1.1, 2667104.06] => 1 (expected 1)\n",
      "[1.0, 3029956.79] => 1 (expected 1)\n",
      "[1.08, 2749718.75] => 1 (expected 1)\n",
      "[0.85, 3323882.38] => 1 (expected 1)\n",
      "[0.73, 5070580.56] => 1 (expected 1)\n",
      "[1.08, 2893717.97] => 1 (expected 1)\n",
      "[1.15, 2653023.23] => 1 (expected 1)\n",
      "[1.28, 2409159.6] => 1 (expected 1)\n",
      "[1.04, 2725856.44] => 1 (expected 1)\n",
      "[1.21, 52474.67] => 1 (expected 1)\n",
      "[1.11, 53170.36] => 1 (expected 1)\n",
      "[1.14, 51913.12] => 1 (expected 1)\n",
      "[1.23, 43059.51] => 1 (expected 1)\n",
      "[1.33, 42934.45] => 1 (expected 1)\n",
      "[1.34, 45689.27] => 1 (expected 1)\n",
      "[1.31, 49201.89] => 1 (expected 1)\n",
      "[1.42, 48697.16] => 1 (expected 1)\n",
      "[1.36, 52815.97] => 1 (expected 1)\n",
      "[1.41, 48799.38] => 1 (expected 1)\n",
      "[1.62, 33737.71] => 1 (expected 1)\n",
      "[1.72, 28062.63] => 1 (expected 1)\n",
      "[1.68, 34443.27] => 1 (expected 1)\n",
      "[1.51, 38333.16] => 1 (expected 1)\n",
      "[1.57, 43450.79] => 1 (expected 1)\n",
      "[1.66, 45533.58] => 1 (expected 1)\n",
      "[1.6, 40540.88] => 1 (expected 1)\n",
      "[1.58, 40655.43] => 1 (expected 1)\n",
      "[1.52, 50234.03] => 1 (expected 1)\n",
      "[1.55, 39542.9] => 1 (expected 1)\n",
      "[1.61, 35630.99] => 1 (expected 1)\n",
      "[1.63, 40544.17] => 1 (expected 1)\n",
      "[1.53, 43803.78] => 1 (expected 1)\n",
      "[1.56, 41636.8] => 1 (expected 1)\n",
      "[1.59, 39171.61] => 1 (expected 1)\n",
      "[1.46, 56929.52] => 1 (expected 1)\n",
      "[1.47, 48421.15] => 1 (expected 1)\n",
      "[1.46, 45352.7] => 1 (expected 1)\n",
      "[1.44, 42369.24] => 1 (expected 1)\n",
      "[1.42, 44034.76] => 1 (expected 1)\n",
      "[1.4, 44605.56] => 1 (expected 1)\n",
      "[1.42, 49071.35] => 1 (expected 1)\n",
      "[1.41, 43907.34] => 1 (expected 1)\n",
      "[1.39, 42131.8] => 1 (expected 1)\n",
      "[1.36, 43115.31] => 1 (expected 1)\n",
      "[1.4, 44090.53] => 1 (expected 1)\n",
      "[1.41, 44688.56] => 1 (expected 1)\n",
      "[1.39, 43407.79] => 1 (expected 1)\n",
      "[1.42, 44984.85] => 1 (expected 1)\n",
      "[1.42, 35121.94] => 1 (expected 1)\n",
      "[1.25, 41439.59] => 1 (expected 1)\n",
      "[1.42, 32656.06] => 1 (expected 1)\n",
      "[1.35, 42280.47] => 1 (expected 1)\n",
      "[1.14, 60244.59] => 1 (expected 1)\n",
      "[1.36, 44972.88] => 1 (expected 1)\n",
      "[1.43, 41524.22] => 1 (expected 1)\n",
      "[1.29, 46991.12] => 1 (expected 1)\n",
      "[1.12, 50107.32] => 1 (expected 1)\n",
      "[1.23, 38078.07] => 1 (expected 1)\n",
      "[1.29, 43649.12] => 1 (expected 1)\n",
      "[1.08, 60232.63] => 1 (expected 1)\n",
      "[1.25, 54495.54] => 1 (expected 1)\n",
      "[1.17, 81458.1] => 1 (expected 1)\n",
      "[1.29, 75362.42] => 1 (expected 1)\n",
      "[1.31, 77692.93] => 1 (expected 1)\n",
      "[1.52, 68500.56] => 1 (expected 1)\n",
      "[1.64, 63734.67] => 1 (expected 1)\n",
      "[1.67, 60249.61] => 1 (expected 1)\n",
      "[1.7, 66733.93] => 1 (expected 1)\n",
      "[1.94, 64388.86] => 1 (expected 1)\n",
      "[2.1, 48849.52] => 1 (expected 1)\n",
      "[2.44, 35647.66] => 1 (expected 1)\n",
      "[1.85, 56666.92] => 1 (expected 1)\n",
      "[1.58, 72073.73] => 1 (expected 1)\n",
      "[1.52, 76112.99] => 1 (expected 1)\n",
      "[1.62, 62154.36] => 1 (expected 1)\n",
      "[1.47, 74445.93] => 1 (expected 1)\n",
      "[1.2, 109755.53] => 1 (expected 1)\n",
      "[1.29, 106844.47] => 1 (expected 1)\n",
      "[1.26, 104270.76] => 1 (expected 1)\n",
      "[1.19, 114354.69] => 1 (expected 1)\n",
      "[1.2, 131165.91] => 1 (expected 1)\n",
      "[1.14, 130613.45] => 1 (expected 1)\n",
      "[1.21, 115313.85] => 1 (expected 1)\n",
      "[1.21, 111080.96] => 1 (expected 1)\n",
      "[1.23, 114343.02] => 1 (expected 1)\n",
      "[1.15, 125690.61] => 1 (expected 1)\n",
      "[1.23, 116296.31] => 1 (expected 1)\n",
      "[1.18, 112304.11] => 1 (expected 1)\n",
      "[1.23, 110087.71] => 1 (expected 1)\n",
      "[1.15, 106514.62] => 1 (expected 1)\n",
      "[1.18, 99717.99] => 1 (expected 1)\n",
      "[1.11, 111714.45] => 1 (expected 1)\n",
      "[0.98, 115978.52] => 1 (expected 1)\n",
      "[1.14, 108031.14] => 1 (expected 1)\n",
      "[1.13, 119123.05] => 1 (expected 1)\n",
      "[1.11, 102002.62] => 1 (expected 1)\n",
      "[1.04, 117010.57] => 1 (expected 1)\n",
      "[1.01, 106228.91] => 1 (expected 1)\n",
      "[1.05, 108798.33] => 1 (expected 1)\n",
      "[1.08, 117966.34] => 1 (expected 1)\n",
      "[1.07, 104358.7] => 1 (expected 1)\n",
      "[1.1, 96605.4] => 1 (expected 1)\n",
      "[1.09, 117245.31] => 1 (expected 1)\n",
      "[0.96, 115143.8] => 1 (expected 1)\n",
      "[0.96, 128489.58] => 1 (expected 1)\n",
      "[1.07, 91664.08] => 1 (expected 1)\n",
      "[1.09, 89422.16] => 1 (expected 1)\n",
      "[1.07, 80943.91] => 1 (expected 1)\n",
      "[1.02, 81433.73] => 1 (expected 1)\n",
      "[1.06, 79706.09] => 1 (expected 1)\n",
      "[1.18, 65863.8] => 1 (expected 1)\n",
      "[1.08, 80027.43] => 1 (expected 1)\n",
      "[1.15, 60896.62] => 1 (expected 1)\n",
      "[1.74, 78872.75] => 1 (expected 1)\n",
      "[1.8, 69804.27] => 1 (expected 1)\n",
      "[1.7, 64716.36] => 1 (expected 1)\n",
      "[1.78, 69862.39] => 1 (expected 1)\n",
      "[1.77, 71010.03] => 1 (expected 1)\n",
      "[2.01, 59523.55] => 1 (expected 1)\n",
      "[1.99, 61451.23] => 1 (expected 1)\n",
      "[1.98, 62337.67] => 1 (expected 1)\n",
      "[1.72, 73723.79] => 1 (expected 1)\n",
      "[1.99, 67050.78] => 1 (expected 1)\n",
      "[1.99, 68637.55] => 1 (expected 1)\n",
      "[2.12, 57490.8] => 1 (expected 1)\n",
      "[2.28, 59194.04] => 1 (expected 1)\n",
      "[2.1, 65405.61] => 1 (expected 1)\n",
      "[2.03, 73696.3] => 1 (expected 1)\n",
      "[2.32, 64855.01] => 1 (expected 1)\n",
      "[2.32, 64680.12] => 1 (expected 1)\n",
      "[2.11, 70419.78] => 1 (expected 1)\n",
      "[2.37, 63222.41] => 1 (expected 1)\n",
      "[2.16, 75146.55] => 1 (expected 1)\n",
      "[2.04, 72817.55] => 1 (expected 1)\n",
      "[2.1, 67080.63] => 1 (expected 1)\n",
      "[2.1, 67790.94] => 1 (expected 1)\n",
      "[2.07, 70179.47] => 1 (expected 1)\n",
      "[2.02, 75021.72] => 1 (expected 1)\n",
      "[1.42, 120562.92] => 1 (expected 1)\n",
      "[1.46, 109111.93] => 1 (expected 1)\n",
      "[1.37, 109872.63] => 1 (expected 1)\n",
      "[1.37, 108808.01] => 1 (expected 1)\n",
      "[1.35, 106703.23] => 1 (expected 1)\n",
      "[1.28, 128923.07] => 1 (expected 1)\n",
      "[1.37, 122886.52] => 1 (expected 1)\n",
      "[1.42, 114120.43] => 1 (expected 1)\n",
      "[1.4, 105965.36] => 1 (expected 1)\n",
      "[1.31, 137484.97] => 1 (expected 1)\n",
      "[1.25, 127255.45] => 1 (expected 1)\n",
      "[1.25, 127222.31] => 1 (expected 1)\n",
      "[1.31, 122876.89] => 1 (expected 1)\n",
      "[1.3, 118305.22] => 1 (expected 1)\n",
      "[1.3, 122384.82] => 1 (expected 1)\n",
      "[1.33, 125710.73] => 1 (expected 1)\n",
      "[1.25, 135636.51] => 1 (expected 1)\n",
      "[1.19, 143848.91] => 1 (expected 1)\n",
      "[1.07, 146065.71] => 1 (expected 1)\n",
      "[1.05, 143520.74] => 1 (expected 1)\n",
      "[1.19, 115734.75] => 1 (expected 1)\n",
      "[1.17, 95227.6] => 1 (expected 1)\n",
      "[1.19, 91687.96] => 1 (expected 1)\n",
      "[1.09, 99597.27] => 1 (expected 1)\n",
      "[1.27, 77418.61] => 1 (expected 1)\n",
      "[1.3, 86845.72] => 1 (expected 1)\n",
      "[1.19, 112953.28] => 1 (expected 1)\n",
      "[1.07, 99950.32] => 1 (expected 1)\n",
      "[1.74, 91739.92] => 1 (expected 1)\n",
      "[1.72, 93566.16] => 1 (expected 1)\n",
      "[1.39, 141932.83] => 1 (expected 1)\n",
      "[1.4, 145608.11] => 1 (expected 1)\n",
      "[1.74, 90985.4] => 1 (expected 1)\n",
      "[1.88, 88854.41] => 1 (expected 1)\n",
      "[1.74, 92968.52] => 1 (expected 1)\n",
      "[1.6, 100274.88] => 1 (expected 1)\n",
      "[1.73, 97026.15] => 1 (expected 1)\n",
      "[1.75, 94441.5] => 1 (expected 1)\n",
      "[1.68, 106624.63] => 1 (expected 1)\n",
      "[1.8, 87517.23] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "x = X[:1]\n",
    "## Costo 1.25, total vendido 12000.64 seria Los Angeles\n",
    "## Costo \n",
    "a = np.array([1.25, 12000.64])\n",
    "dummy = a[np.newaxis, :]\n",
    "predictions = model.predict_classes(dummy)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "x = X[:1]\n",
    "## Costo 1.16, total vendido 15000.82 seria Los Angeles\n",
    "## Costo \n",
    "a = np.array([1.16, 15000.82])\n",
    "dummy = a[np.newaxis, :]\n",
    "predictions = model.predict_classes(dummy)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "x = X[:1]\n",
    "## Costo 1.89, total vendido 8000.53 seria Los Angeles\n",
    "## Costo \n",
    "a = np.array([1.89, 8000.53])\n",
    "dummy = a[np.newaxis, :]\n",
    "predictions = model.predict_classes(dummy)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[:1]\n",
    "## Costo 1.89, total vendido 8000.53 seria Los Angeles\n",
    "## Costo \n",
    "a = np.array([1.89, 8000.53])\n",
    "dummy = a[np.newaxis, :]\n",
    "predictions = model.predict_classes(dummy)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
